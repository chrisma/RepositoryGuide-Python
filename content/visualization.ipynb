{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is responsible for visualizing the data from the Github API, which should be provided in a serialized format.\n",
    "\n",
    "Requirement: It must be possible to run this notebook using JupyterLite.\n",
    "\n",
    "For an exemplary use case, please see the project's `README.md`.\n",
    "\n",
    "Important aspects of the different cells, and how to use them are explained in markdown comments above them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting:\n",
    "\n",
    "#### Even after reloading (deep-refreshing) the page, a notebook is not updated\n",
    "\n",
    "This likely occurred because the backend and frontend of jupyterlite are out of sync.\n",
    "I am not yet sure why this happens even after a deep-refresh of the page, as this should update the frontend according to the jupyterlite documentation.\n",
    "As a workaround, delete the cache/cookies for the page and reload it.\n",
    "Note that you this will reset all notebooks to their versions saved on Github, so download your notebooks if necessary.\n",
    "You will also have to re-run the notebooks.\n",
    "\n",
    "An additional necessary step may be to \"delete\" the files in question in jupyterlite, which should refresh them with the version on Github.\n",
    "\n",
    "#### The `commits.json` cannot be found when it is being loaded\n",
    "\n",
    "Same reasoning & workaround as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We need to install dependecies for the frontend separately in JupyterLite\n",
    "%pip install ipywidgets plotly pandas tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets\n",
    "from IPython import display\n",
    "import tabulate #https://pypi.org/project/tabulate/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('commits.json') as f:\n",
    "    data = json.load(f)\n",
    "    df = pd.json_normalize(data)\n",
    "df['_date'] = df.apply(lambda row: pd.to_datetime(row['commit.author.date'], format='%Y-%m-%dT%H:%M:%SZ'), axis='columns')\n",
    "df['_merge_commit'] = df.apply(lambda row: len(row['parents']) >= 2, axis='columns')\n",
    "cs = df[~df['_merge_commit'] & ~df['author.login'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display.display(tabulate.tabulate(\n",
    "    [[\"Retrieved commits from repository:\", len(df)],\n",
    "     [\"Merge commits that are excluded:\", len(df[df['_merge_commit']])],\n",
    "     [\"Non-merge commits missing GitHub user:\", len(df[~df['_merge_commit'] & df['author.login'].isna()])],\n",
    "     [\"Amount of qualifying commits:\", len(cs)],\n",
    "     [\"Unique authors in qualifying commits:\", len(cs['author.login'].unique())],\n",
    "     [\"Earliest commit:\", cs['_date'].min().date()],\n",
    "     [\"Latest commit:\", cs['_date'].max().date()]\n",
    "    ], tablefmt='html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[~df['_merge_commit'] & df['author.login'].isna()] \\\n",
    "    .groupby(['commit.author.name','commit.author.email','commit.committer.name','commit.committer.email'], as_index=False) \\\n",
    "    .size() \\\n",
    "    .style.set_caption(\"Information of commits not assigned to GitHub users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Input data ranges of sprints\n",
    "#\n",
    "sprints_out = ipywidgets.Output()\n",
    "sprints_out.append_display_data(ipywidgets.Label(value=\"Set the number of sprints to be used as the basis of analysis:\"))\n",
    "num_sprints = ipywidgets.BoundedIntText(value=1, min=1, step=1, description='Number of sprints:', style=dict(description_width='initial'))\n",
    "sprints_out.append_display_data(num_sprints)\n",
    "sprints_out.append_display_data(ipywidgets.Label(value=\"Set start and end dates for each sprint:\"))\n",
    "sprint_names, start_dates, end_dates = [], [], []\n",
    "\n",
    "# Initialize the widgets for the first sprint\n",
    "sprint_names.append(ipywidgets.Text(value=\"All time\", placeholder='Name to be displayed', description='Sprint Name:'))\n",
    "start_dates.append(ipywidgets.DatePicker(value=cs['_date'].min().date(), description='Start Date'))\n",
    "end_dates.append(ipywidgets.DatePicker(value=cs['_date'].max().date(), description='End Date'))\n",
    "sprints_out.append_display_data(sprint_names[0])\n",
    "sprints_out.append_display_data(start_dates[0])\n",
    "sprints_out.append_display_data(end_dates[0])\n",
    "\n",
    "# Automatically add/remove the widgets based on the number of sprints\n",
    "def update_sprints(change):\n",
    "\tif change['type'] == 'change' and change['name'] == 'value':\n",
    "\t\tif change['new'] > change['old']:\n",
    "\t\t\t# Only add a new widget if we do not have one with this \"number\" already\n",
    "\t\t\tif len(sprint_names) < change['new']:\n",
    "\t\t\t\tsprint_names.append(ipywidgets.Text(value=f'Sprint {change[\"new\"]}', placeholder='Set the name for this Sprint', description='Sprint Name:'))\n",
    "\t\t\t\tstart_dates.append(ipywidgets.DatePicker(description='Start Date'))\n",
    "\t\t\t\tend_dates.append(ipywidgets.DatePicker(description='End Date'))\n",
    "\t\t\t# Display the necessary widgets for the new sprint\n",
    "\t\t\tsprints_out.append_display_data(sprint_names[change[\"new\"] - 1])\n",
    "\t\t\tsprints_out.append_display_data(start_dates[change[\"new\"] - 1])\n",
    "\t\t\tsprints_out.append_display_data(end_dates[change[\"new\"] - 1])\n",
    "\t\telif change['new'] < change['old']:\n",
    "\t\t\t# Remove the widgets for the removed sprint (workaround, as clear_output() will not work here, as we are using append_display_data() instead of the 'with out:' syntax)\n",
    "\t\t\tsprints_out.outputs = sprints_out.outputs[:-3]\n",
    "\n",
    "num_sprints.observe(update_sprints, names='value')\n",
    "\n",
    "display.display(sprints_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sprint_data = []\n",
    "for i, name in enumerate(sprint_names):\n",
    "    start = datetime.combine(start_dates[i].value, datetime.min.time())\n",
    "    end = datetime.combine(end_dates[i].value, datetime.max.time())\n",
    "    sprint_data.append({\n",
    "        'name': name.value, \n",
    "        'start': start,\n",
    "        'end': end\n",
    "    })\n",
    "\n",
    "#sprints = pd.DataFrame(sprint_data)\n",
    "#bins = sprints['_sprint.start'].to_list() + [sprints.iloc[-1]['_sprint.end']]\n",
    "#pd.cut(cs['_date'], bins, labels=sprints['_sprint.name'], include_lowest=True)\n",
    "\n",
    "def assign_to_sprint(row):\n",
    "    for sprint in sprint_data:\n",
    "        if sprint['start'] <= row['_date'] < sprint['end']:\n",
    "            return sprint['name'], sprint['start'], sprint['end']\n",
    "    return np.nan, np.nan, np.nan\n",
    "\n",
    "cs[['_sprint.name', '_sprint.start', '_sprint.end']] = cs.apply(assign_to_sprint, axis='columns', result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Input teams and team members\n",
    "#\n",
    "teams_output = ipywidgets.Output()\n",
    "teams_output.append_display_data(ipywidgets.Label(value=\"Set the number of teams using the slider, and the text fields to set names for each team.\"))\n",
    "num_teams = ipywidgets.IntSlider(min=1, max=10, step=1, description='No. of teams')\n",
    "teams_output.append_display_data(num_teams)\n",
    "teams_output.append_display_data(ipywidgets.Label(value=\"Upload a JSON file of with a list of team members in the format `['githubUsername', 'anotherUsername']`\"))\n",
    "\n",
    "team_names = []\n",
    "team_files = []\n",
    "team_members = []\n",
    "\n",
    "# Handler for the file upload widgets\n",
    "def handle_upload(change):\n",
    "\t# Only handle the upload if the file is not empty\n",
    "\tif change['new']:\n",
    "\t\t# Get the team index from the name of the widget\n",
    "\t\tteam_index = int(change['owner'].description.split(' ')[2]) - 1\n",
    "\t\t# Get the file name and content\n",
    "\t\tuploaded_file = next(iter(team_files[team_index].value))\n",
    "\t\twith open(uploaded_file.name, 'wb') as f:\n",
    "\t\t\tf.write(uploaded_file.content)\n",
    "\t\twith open(uploaded_file.name) as f:\n",
    "\t\t\tteam_members[team_index] = json.load(f)\n",
    "\t\tprint(f'Uploaded file {uploaded_file.name} for team {team_names[i].value}')\n",
    "\t\t# Print the team members\n",
    "\t\tprint(f'Team members:')\n",
    "\t\tprint(\"\\n\".join(team_members[team_index]))\n",
    "\t\tprint()\n",
    "\n",
    "# Initialize the widgets for the first team\n",
    "team_names.append(ipywidgets.Text(value=f'Team 1', placeholder='Set the name for this Team', description='Team Name:'))\n",
    "team_files.append(ipywidgets.FileUpload(description=f'Upload Team 1', accept='.json'))\n",
    "team_members.append([])\n",
    "teams_output.append_display_data(team_names[0])\n",
    "teams_output.append_display_data(team_files[0])\n",
    "\n",
    "# Register the upload handler for the first team\n",
    "team_files[0].observe(handle_upload, names='value')\n",
    "\n",
    "# Automatically add/remove the widgets based on the number of teams\n",
    "def update_teams(change):\n",
    "\tif change['type'] == 'change' and change['name'] == 'value':\n",
    "\t\tif change['new'] > change['old']:\n",
    "\t\t\t# Only add a new widget if we do not have one with this \"number\" already\n",
    "\t\t\tif len(team_names) < change['new']:\n",
    "\t\t\t\tteam_names.append(ipywidgets.Text(value=f'Team {change[\"new\"]}', placeholder='Set the name for this Team', description='Team Name:'))\n",
    "\t\t\t\tteam_files.append(ipywidgets.FileUpload(description=f'Upload Team {change[\"new\"]}', accept='.json'))\n",
    "\t\t\t\tteam_members.append([])\n",
    "\t\t\t\t# Register the upload handler for the new team\n",
    "\t\t\t\tteam_files[-1].observe(handle_upload, names='value')\n",
    "\t\t\t# Display the necessary widgets for the new team\n",
    "\t\t\tteams_output.append_display_data(team_names[change[\"new\"] - 1])\n",
    "\t\t\tteams_output.append_display_data(team_files[change[\"new\"] - 1])\n",
    "\t\telif change['new'] < change['old']:\n",
    "\t\t\t# Remove the widgets for the removed team (workaround, as clear_output() will not work here, as we are using append_display_data() instead of the 'with out:' syntax)\n",
    "\t\t\tteams_output.outputs = teams_output.outputs[:-2]\n",
    "\n",
    "num_teams.observe(update_teams, names='value')\n",
    "\n",
    "display.display(teams_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "team_data = []\n",
    "for i, team in enumerate(team_members):\n",
    "    for login in team:\n",
    "        team_data.append({'author.login': login, '_team.name': team_names[i].value})\n",
    "teams = pd.DataFrame(team_data)\n",
    "# teams.style.hide(axis='index').set_caption('Teams and members')\n",
    "\n",
    "cst = pd.merge(cs, teams, how='outer', on='author.login')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unassigned = cst[cst['_team.name'].isna()] \\\n",
    "    .groupby(['author.login'], as_index=False) \\\n",
    "    .size().sort_values(['size'],ascending=False)\n",
    "# unassigned.style.hide(axis='index').set_caption(\"GitHub users w/o team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts = cst.fillna({'_team.name':'unassigned'}) \\\n",
    "    .groupby(['_team.name','author.login'], as_index=False) \\\n",
    "    .count().rename(columns = {'sha':'count'}) \\\n",
    "    .sort_values(by=['count'])\n",
    "# counts[['_team.name','author.login','count']]\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "for team in counts['_team.name'].unique():\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=counts.loc[counts['_team.name'] == team]['count'],\n",
    "        y=counts.loc[counts['_team.name'] == team]['author.login'],\n",
    "        name=team,\n",
    "        orientation='h'\n",
    "    ))\n",
    "fig.update_layout(\n",
    "    xaxis_title=f\"Total non-merge commits by authors from {cst['_date'].min().date()} to {cst['_date'].max().date()}\",\n",
    "    yaxis_title=\"GitHub Login\",\n",
    "    height=20*len(counts['author.login'].unique()),\n",
    "    yaxis2=dict(range=[0,1], visible=False)\n",
    ")\n",
    "# https://community.plotly.com/t/i-want-to-draw-line-markers-on-a-bar-plot/31020\n",
    "mean = np.round(np.mean(counts['count']),decimals=1)\n",
    "line = go.Scatter(x=[mean,mean], name='avg.')\n",
    "fig.add_trace(line, 1, 1, secondary_y=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def time_of_day(date):\n",
    "    hour = date.hour\n",
    "    if hour <= 7 or hour >= 22:\n",
    "        return 0 # \"night\"\n",
    "    elif hour <= 12:\n",
    "        return 1 # \"morning\"\n",
    "    elif hour <= 17:\n",
    "        return 2 # \"afternoon\"\n",
    "    else:\n",
    "        return 3 # \"evening\"\n",
    "\n",
    "def commit_heatmap(team=None, sprint=None):\n",
    "    data = cst[~cst['_date'].isna()]\n",
    "    if team:\n",
    "        data = data.loc[data['_team.name'] == team]\n",
    "    if sprint:\n",
    "        data = data.loc[data['_sprint.name'] == sprint]\n",
    "    \n",
    "    fig_params = [\n",
    "        {'x': [d.hour for d in data['_date']],\n",
    "         'nbinsx': 24,\n",
    "         'xaxis_title': 'Hour',\n",
    "         'xaxis_tickvals': np.arange(0, 24, 1),\n",
    "         'xaxis_ticktext': np.arange(0, 24, 1)},\n",
    "        {'x': [time_of_day(d) for d in data['_date']],\n",
    "         'nbinsx': 4,\n",
    "         'xaxis_title': 'Time of Day',\n",
    "         'xaxis_tickvals': np.arange(0, 4),\n",
    "         'xaxis_ticktext': ['Night (22-7)', 'Morning (7-12)', 'Afternoon (12-17)', 'Evening (17-22)']}\n",
    "    ]\n",
    "\n",
    "    sub_tabs = []\n",
    "    for i, params in enumerate(fig_params):\n",
    "        fig = px.density_heatmap(\n",
    "            x=params['x'],\n",
    "            y=[d.weekday() for d in data['_date']],\n",
    "            nbinsx=params['nbinsx'],\n",
    "            nbinsy=7,\n",
    "            histfunc='count',\n",
    "            text_auto=True)\n",
    "        fig.update_layout(\n",
    "            title=f\"Commit heatmap of '{team if team else 'All'}' for time '{sprint if sprint else 'All'}'\",\n",
    "            xaxis=dict(\n",
    "                title = params['xaxis_title'],\n",
    "                tickvals = params['xaxis_tickvals'],\n",
    "                ticktext = params['xaxis_ticktext']\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title = 'Day of the week',\n",
    "                tickvals = np.arange(0, 7),\n",
    "                ticktext = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "            ))\n",
    "        out = ipywidgets.Output()\n",
    "        with out:\n",
    "            fig.show()\n",
    "            sub_tabs.append(out)\n",
    "\n",
    "    tab = ipywidgets.Tab(children=sub_tabs, titles=['By hour', 'By time of day'])\n",
    "    display.display(tab)\n",
    "\n",
    "interactive_plot = ipywidgets.interactive(\n",
    "    commit_heatmap,\n",
    "    team=[('All', None)] + [(n, n) for n in cst['_team.name'].dropna().unique()],\n",
    "    sprint=[('All', None)] + [(n, n) for n in cst['_sprint.name'].dropna().unique()])\n",
    "display.display(interactive_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "067b78e4a44e8b0a0f6f4f23266782a314d21c0d58909bd8030b6a0c0eed9a04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
